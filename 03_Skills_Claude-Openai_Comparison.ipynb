{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챕터 3: OpenAI API Endpoint와 비교하여 구현\n",
    "\n",
    "## 3-1. Claude API vs OpenAI API 개요\n",
    "\n",
    "두 API의 주요 차이점:\n",
    "- **메시지 구조**: 둘 다 messages 배열을 사용하지만 세부 구조가 다르다\n",
    "- **System Prompt**: Claude는 system 파라미터, OpenAI는 messages 내 system role\n",
    "- **응답 형식**: 응답 구조가 다르다\n",
    "- **모델 이름**: 각자 다른 모델명을 사용한다\n",
    "\n",
    "이번 챕터에서는 두 API를 모두 지원하는 통합 Skills 시스템을 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "%pip install -q anthropic openai python-dotenv pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Dict, List, Optional, Union, Literal\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "\n",
    "print(\"라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. API 제공자 열거형 정의\n",
    "\n",
    "지원하는 AI 제공자를 명확히 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAUDE_MODEL = \"claude-sonnet-4-5\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 설정 완료\n",
      "  - Anthropic 기본 모델: claude-sonnet-4-5\n",
      "  - OpenAI 기본 모델: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "class AIProvider(Enum):\n",
    "    \"\"\"\n",
    "    지원하는 AI API 제공자\n",
    "    \"\"\"\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    OPENAI = \"openai\"\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"\n",
    "    각 제공자별 모델 설정\n",
    "    \"\"\"\n",
    "    provider: AIProvider\n",
    "    model_name: str\n",
    "    max_tokens: int = 2000\n",
    "    temperature: float = 0.7\n",
    "\n",
    "# 각 제공자별 기본 모델 설정\n",
    "DEFAULT_MODELS = {\n",
    "    AIProvider.ANTHROPIC: ModelConfig(\n",
    "        provider=AIProvider.ANTHROPIC,\n",
    "        model_name=CLAUDE_MODEL,\n",
    "        max_tokens=2000\n",
    "    ),\n",
    "    AIProvider.OPENAI: ModelConfig(\n",
    "        provider=AIProvider.OPENAI,\n",
    "        model_name=OPENAI_MODEL,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"모델 설정 완료\")\n",
    "print(f\"  - Anthropic 기본 모델: {DEFAULT_MODELS[AIProvider.ANTHROPIC].model_name}\")\n",
    "print(f\"  - OpenAI 기본 모델: {DEFAULT_MODELS[AIProvider.OPENAI].model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. 추상 베이스 클래스로 AI Client 인터페이스 정의\n",
    "\n",
    "다양한 AI 제공자를 지원하기 위한 공통 인터페이스를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIClient 추상 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class AIClient(ABC):\n",
    "    \"\"\"\n",
    "    AI API 클라이언트의 추상 베이스 클래스\n",
    "    모든 AI 제공자는 이 인터페이스를 구현해야 한다\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        클라이언트를 초기화한다\n",
    "        \n",
    "        Args:\n",
    "            api_key: API 키 (None이면 환경 변수에서 가져온다)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def create_completion(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        user_message: str,\n",
    "        model: str,\n",
    "        max_tokens: int,\n",
    "        temperature: float\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        AI 모델에게 completion을 요청한다\n",
    "        \n",
    "        Args:\n",
    "            system_prompt: 시스템 프롬프트 (Skill 내용)\n",
    "            user_message: 사용자 메시지\n",
    "            model: 사용할 모델 이름\n",
    "            max_tokens: 최대 토큰 수\n",
    "            temperature: 온도 파라미터\n",
    "            \n",
    "        Returns:\n",
    "            AI의 응답 텍스트\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_provider(self) -> AIProvider:\n",
    "        \"\"\"\n",
    "        현재 클라이언트의 제공자를 반환한다\n",
    "        \n",
    "        Returns:\n",
    "            AIProvider 열거형\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "print(\"AIClient 추상 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Anthropic Client 구현\n",
    "\n",
    "Claude API를 사용하는 클라이언트를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnthropicClient 구현 완료\n"
     ]
    }
   ],
   "source": [
    "class AnthropicClient(AIClient):\n",
    "    \"\"\"\n",
    "    Anthropic Claude API 클라이언트\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Anthropic 클라이언트를 초기화한다\n",
    "        \n",
    "        Args:\n",
    "            api_key: Anthropic API 키\n",
    "        \"\"\"\n",
    "        self.client = anthropic.Anthropic(\n",
    "            api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "        )\n",
    "    \n",
    "    def create_completion(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        user_message: str,\n",
    "        model: str,\n",
    "        max_tokens: int,\n",
    "        temperature: float = 0.7\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Claude API를 호출하여 completion을 생성한다\n",
    "        \n",
    "        Claude API 특징:\n",
    "        - system 파라미터로 시스템 프롬프트를 전달한다\n",
    "        - messages 배열에는 user/assistant role만 포함한다\n",
    "        - response.content[0].text로 응답을 추출한다\n",
    "        \"\"\"\n",
    "        response = self.client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            system=system_prompt,  # Claude는 system을 별도 파라미터로 받는다\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.content[0].text\n",
    "    \n",
    "    def get_provider(self) -> AIProvider:\n",
    "        return AIProvider.ANTHROPIC\n",
    "\n",
    "print(\"AnthropicClient 구현 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. OpenAI Client 구현\n",
    "\n",
    "OpenAI API를 사용하는 클라이언트를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIClient 구현 완료\n"
     ]
    }
   ],
   "source": [
    "class OpenAIClient(AIClient):\n",
    "    \"\"\"\n",
    "    OpenAI API 클라이언트\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        OpenAI 클라이언트를 초기화한다\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API 키\n",
    "        \"\"\"\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "    \n",
    "    def create_completion(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        user_message: str,\n",
    "        model: str,\n",
    "        max_tokens: int,\n",
    "        temperature: float = 0.7\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        OpenAI API를 호출하여 completion을 생성한다\n",
    "        \n",
    "        OpenAI API 특징:\n",
    "        - messages 배열 내에 system role을 포함한다\n",
    "        - system 메시지를 첫 번째로 배치한다\n",
    "        - response.choices[0].message.content로 응답을 추출한다\n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",  # OpenAI는 messages 배열 안에 system을 넣는다\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def get_provider(self) -> AIProvider:\n",
    "        return AIProvider.OPENAI\n",
    "\n",
    "print(\"OpenAIClient 구현 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6. 통합 Skill Agent 구현\n",
    "\n",
    "두 API 제공자를 모두 지원하는 통합 에이전트를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnifiedSkillAgent 구현 완료\n"
     ]
    }
   ],
   "source": [
    "class UnifiedSkillAgent:\n",
    "    \"\"\"\n",
    "    여러 AI 제공자를 지원하는 통합 Skill Agent\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        provider: AIProvider = AIProvider.ANTHROPIC,\n",
    "        anthropic_api_key: Optional[str] = None,\n",
    "        openai_api_key: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        통합 에이전트를 초기화한다\n",
    "        \n",
    "        Args:\n",
    "            provider: 기본으로 사용할 AI 제공자\n",
    "            anthropic_api_key: Anthropic API 키\n",
    "            openai_api_key: OpenAI API 키\n",
    "        \"\"\"\n",
    "        self.provider = provider\n",
    "        self.clients: Dict[AIProvider, AIClient] = {}\n",
    "        \n",
    "        # Anthropic 클라이언트 초기화\n",
    "        try:\n",
    "            self.clients[AIProvider.ANTHROPIC] = AnthropicClient(anthropic_api_key)\n",
    "            print(f\"Anthropic 클라이언트 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"Anthropic 클라이언트 초기화 실패: {e}\")\n",
    "        \n",
    "        # OpenAI 클라이언트 초기화\n",
    "        try:\n",
    "            self.clients[AIProvider.OPENAI] = OpenAIClient(openai_api_key)\n",
    "            print(f\"OpenAI 클라이언트 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI 클라이언트 초기화 실패: {e}\")\n",
    "        \n",
    "        # Skill 저장소\n",
    "        self.skills: Dict[str, Dict] = {}\n",
    "    \n",
    "    def set_provider(self, provider: AIProvider) -> None:\n",
    "        \"\"\"\n",
    "        기본 AI 제공자를 변경한다\n",
    "        \n",
    "        Args:\n",
    "            provider: 새로운 기본 제공자\n",
    "        \"\"\"\n",
    "        if provider not in self.clients:\n",
    "            raise ValueError(f\"{provider.value} 클라이언트가 초기화되지 않았다\")\n",
    "        self.provider = provider\n",
    "        print(f\"기본 제공자를 {provider.value}로 변경했다\")\n",
    "    \n",
    "    def load_skill_from_file(self, skill_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        파일에서 Skill을 로드한다\n",
    "        \n",
    "        Args:\n",
    "            skill_path: Skill 파일 경로 (.yaml 또는 .md)\n",
    "            \n",
    "        Returns:\n",
    "            로드된 Skill 데이터\n",
    "        \"\"\"\n",
    "        path = Path(skill_path)\n",
    "        \n",
    "        if path.suffix == '.yaml':\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                skill_data = yaml.safe_load(f)\n",
    "        elif path.suffix == '.md':\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            skill_data = {\n",
    "                'name': path.stem,\n",
    "                'content': content,\n",
    "                'version': '1.0.0'\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 파일 형식이다: {path.suffix}\")\n",
    "        \n",
    "        skill_name = skill_data['name']\n",
    "        self.skills[skill_name] = skill_data\n",
    "        print(f\"Skill '{skill_name}' 로드 완료\")\n",
    "        \n",
    "        return skill_data\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        skill_name: str,\n",
    "        user_message: str,\n",
    "        provider: Optional[AIProvider] = None,\n",
    "        model: Optional[str] = None,\n",
    "        max_tokens: Optional[int] = None,\n",
    "        temperature: Optional[float] = None\n",
    "    ) -> Dict[str, Union[str, AIProvider]]:\n",
    "        \"\"\"\n",
    "        Skill을 실행하여 AI 응답을 생성한다\n",
    "        \n",
    "        Args:\n",
    "            skill_name: 실행할 Skill 이름\n",
    "            user_message: 사용자 메시지\n",
    "            provider: 사용할 AI 제공자 (None이면 기본값)\n",
    "            model: 사용할 모델 (None이면 기본값)\n",
    "            max_tokens: 최대 토큰 수\n",
    "            temperature: 온도 파라미터\n",
    "            \n",
    "        Returns:\n",
    "            응답 딕셔너리 (response, provider, model 포함)\n",
    "        \"\"\"\n",
    "        # Skill 확인\n",
    "        if skill_name not in self.skills:\n",
    "            raise ValueError(f\"Skill '{skill_name}'을 찾을 수 없다\")\n",
    "        \n",
    "        skill_data = self.skills[skill_name]\n",
    "        \n",
    "        # 제공자 결정\n",
    "        selected_provider = provider or self.provider\n",
    "        if selected_provider not in self.clients:\n",
    "            raise ValueError(f\"{selected_provider.value} 클라이언트를 사용할 수 없다\")\n",
    "        \n",
    "        client = self.clients[selected_provider]\n",
    "        \n",
    "        # 모델 설정 결정 (우선순위: 파라미터 > Skill 설정 > 기본값)\n",
    "        skill_config = skill_data.get('config', {})\n",
    "        default_config = DEFAULT_MODELS[selected_provider]\n",
    "        \n",
    "        final_model = model or skill_config.get('model') or default_config.model_name\n",
    "        final_max_tokens = max_tokens or skill_config.get('max_tokens') or default_config.max_tokens\n",
    "        final_temperature = temperature if temperature is not None else skill_config.get('temperature', default_config.temperature)\n",
    "        \n",
    "        # AI API 호출\n",
    "        response_text = client.create_completion(\n",
    "            system_prompt=skill_data['content'],\n",
    "            user_message=user_message,\n",
    "            model=final_model,\n",
    "            max_tokens=final_max_tokens,\n",
    "            temperature=final_temperature\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'response': response_text,\n",
    "            'provider': selected_provider,\n",
    "            'model': final_model\n",
    "        }\n",
    "    \n",
    "    def list_skills(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        로드된 모든 Skill 목록을 반환한다\n",
    "        \n",
    "        Returns:\n",
    "            Skill 이름 리스트\n",
    "        \"\"\"\n",
    "        return list(self.skills.keys())\n",
    "    \n",
    "    def list_available_providers(self) -> List[AIProvider]:\n",
    "        \"\"\"\n",
    "        사용 가능한 AI 제공자 목록을 반환한다\n",
    "        \n",
    "        Returns:\n",
    "            AIProvider 리스트\n",
    "        \"\"\"\n",
    "        return list(self.clients.keys())\n",
    "\n",
    "print(\"UnifiedSkillAgent 구현 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7. 테스트용 Skill 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역가 Skill 생성: skills_comparison/translator.yaml\n"
     ]
    }
   ],
   "source": [
    "# skills 디렉토리 생성\n",
    "skills_dir = Path(\"skills/skills_comparison\")\n",
    "skills_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 번역가 Skill 생성\n",
    "translator_skill = \"\"\"# 전문 번역가 Skill\n",
    "\n",
    "## 역할\n",
    "텍스트를 자연스럽고 정확하게 번역하는 전문 번역가다.\n",
    "\n",
    "## 번역 원칙\n",
    "1. 정확성: 원문의 의미를 정확히 전달한다\n",
    "2. 자연스러움: 목표 언어의 자연스러운 표현을 사용한다\n",
    "3. 문맥 고려: 문맥에 맞는 적절한 단어를 선택한다\n",
    "4. 문화적 적절성: 문화적 차이를 고려한다\n",
    "\n",
    "## 출력 형식\n",
    "- 번역된 텍스트만 출력한다\n",
    "- 추가 설명이나 주석은 요청이 있을 때만 포함한다\n",
    "\n",
    "## 스타일\n",
    "- 문장은 ~다 체를 사용한다\n",
    "- 전문적이고 정확한 어조를 유지한다\n",
    "\"\"\"\n",
    "\n",
    "translator_yaml = {\n",
    "    'name': 'translator',\n",
    "    'version': '1.0.0',\n",
    "    'description': '전문 번역 서비스',\n",
    "    'content': translator_skill,\n",
    "    'config': {\n",
    "        'max_tokens': 1500,\n",
    "        'temperature': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "# YAML 파일로 저장\n",
    "translator_path = skills_dir / 'translator.yaml'\n",
    "with open(translator_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(translator_yaml, f, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "print(f\"번역가 Skill 생성: {translator_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8. 통합 에이전트 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic 클라이언트 초기화 완료\n",
      "OpenAI 클라이언트 초기화 완료\n",
      "\n",
      "사용 가능한 AI 제공자:\n",
      "  - anthropic\n",
      "  - openai\n"
     ]
    }
   ],
   "source": [
    "# 통합 에이전트 생성\n",
    "agent = UnifiedSkillAgent(provider=AIProvider.ANTHROPIC)\n",
    "\n",
    "# 사용 가능한 제공자 확인\n",
    "print(\"\\n사용 가능한 AI 제공자:\")\n",
    "for provider in agent.list_available_providers():\n",
    "    print(f\"  - {provider.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill 'translator' 로드 완료\n",
      "\n",
      "로드된 Skills:\n",
      "  - translator\n"
     ]
    }
   ],
   "source": [
    "# Skill 로드\n",
    "agent.load_skill_from_file('skills/skills_comparison/translator.yaml')\n",
    "\n",
    "print(\"\\n로드된 Skills:\")\n",
    "for skill in agent.list_skills():\n",
    "    print(f\"  - {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "테스트 1: Claude (Anthropic)로 번역\n",
      "================================================================================\n",
      "제공자: anthropic\n",
      "모델: claude-sonnet-4-5\n",
      "\n",
      "번역 결과:\n",
      "인공지능은 우리가 일하고 생활하는 방식을 변화시키고 있다.\n",
      "인공지능은 의료, 금융, 교육 및 기타 많은 분야에서 응용되고 있다.\n"
     ]
    }
   ],
   "source": [
    "# Claude로 번역 테스트\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"테스트 1: Claude (Anthropic)로 번역\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "text_to_translate = \"\"\"\n",
    "Artificial Intelligence is transforming the way we work and live.\n",
    "It has applications in healthcare, finance, education, and many other fields.\n",
    "\"\"\"\n",
    "\n",
    "result1 = agent.execute(\n",
    "    skill_name='translator',\n",
    "    user_message=f\"다음 영어 텍스트를 한국어로 번역해줘:\\n{text_to_translate}\",\n",
    "    provider=AIProvider.ANTHROPIC\n",
    ")\n",
    "\n",
    "print(f\"제공자: {result1['provider'].value}\")\n",
    "print(f\"모델: {result1['model']}\")\n",
    "print(f\"\\n번역 결과:\\n{result1['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "테스트 2: GPT (OpenAI)로 번역\n",
      "================================================================================\n",
      "제공자: openai\n",
      "모델: gpt-4o-mini\n",
      "\n",
      "번역 결과:\n",
      "인공지능은 우리가 일하고 생활하는 방식을 변화시키고 있다. 그것은 의료, 금융, 교육 및 많은 다른 분야에서 응용되고 있다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI로 번역 테스트 (API 키가 설정된 경우)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"테스트 2: GPT (OpenAI)로 번역\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    result2 = agent.execute(\n",
    "        skill_name='translator',\n",
    "        user_message=f\"다음 영어 텍스트를 한국어로 번역해줘:\\n{text_to_translate}\",\n",
    "        provider=AIProvider.OPENAI\n",
    "    )\n",
    "    \n",
    "    print(f\"제공자: {result2['provider'].value}\")\n",
    "    print(f\"모델: {result2['model']}\")\n",
    "    print(f\"\\n번역 결과:\\n{result2['response']}\")\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI 실행 실패: {e}\")\n",
    "    print(\"OpenAI API 키가 설정되지 않았거나 유효하지 않다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-9. 제공자별 비교 테스트\n",
    "\n",
    "동일한 Skill과 입력으로 두 제공자의 응답을 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "제공자별 비교 테스트\n",
      "================================================================================\n",
      "\n",
      "anthropic로 실행 중...\n",
      "\n",
      "openai로 실행 중...\n",
      "\n",
      "[ANTHROPIC]\n",
      "  모델: claude-sonnet-4-5\n",
      "  응답: 안녕하세요, 오늘 어떻게 지내세요?\n",
      "\n",
      "[OPENAI]\n",
      "  모델: gpt-4o-mini\n",
      "  응답: 안녕하세요, 오늘 어떻게 지내세요?\n"
     ]
    }
   ],
   "source": [
    "def compare_providers(\n",
    "    agent: UnifiedSkillAgent,\n",
    "    skill_name: str,\n",
    "    user_message: str\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    여러 제공자로 동일한 작업을 수행하고 결과를 비교한다\n",
    "    \n",
    "    Args:\n",
    "        agent: UnifiedSkillAgent 인스턴스\n",
    "        skill_name: 사용할 Skill 이름\n",
    "        user_message: 사용자 메시지\n",
    "        \n",
    "    Returns:\n",
    "        제공자별 결과 딕셔너리\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for provider in agent.list_available_providers():\n",
    "        try:\n",
    "            print(f\"\\n{provider.value}로 실행 중...\")\n",
    "            result = agent.execute(\n",
    "                skill_name=skill_name,\n",
    "                user_message=user_message,\n",
    "                provider=provider\n",
    "            )\n",
    "            results[provider.value] = result\n",
    "        except Exception as e:\n",
    "            print(f\"{provider.value} 실행 실패: {e}\")\n",
    "            results[provider.value] = {'error': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 비교 테스트 실행\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"제공자별 비교 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_message = \"Hello, how are you today?를 한국어로 번역해줘\"\n",
    "comparison_results = compare_providers(agent, 'translator', comparison_message)\n",
    "\n",
    "# 결과 출력\n",
    "for provider_name, result in comparison_results.items():\n",
    "    print(f\"\\n[{provider_name.upper()}]\")\n",
    "    if 'error' in result:\n",
    "        print(f\"  에러: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"  모델: {result['model']}\")\n",
    "        print(f\"  응답: {result['response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-10. API 호출 비용 및 응답 시간 비교\n",
    "\n",
    "실제 프로덕션 환경에서 고려해야 할 메트릭을 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "제공자별 성능 벤치마크\n",
      "================================================================================\n",
      "\n",
      "[ANTHROPIC]\n",
      "  모델: claude-sonnet-4-5\n",
      "  응답 시간: 3.46초\n",
      "  응답 길이: 24 문자\n",
      "\n",
      "[OPENAI]\n",
      "  모델: gpt-4o-mini\n",
      "  응답 시간: 1.53초\n",
      "  응답 길이: 113 문자\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_providers(\n",
    "    agent: UnifiedSkillAgent,\n",
    "    skill_name: str,\n",
    "    user_message: str\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    제공자별 응답 시간을 측정한다\n",
    "    \n",
    "    Args:\n",
    "        agent: UnifiedSkillAgent 인스턴스\n",
    "        skill_name: 사용할 Skill 이름\n",
    "        user_message: 사용자 메시지\n",
    "        \n",
    "    Returns:\n",
    "        제공자별 벤치마크 결과\n",
    "    \"\"\"\n",
    "    benchmarks = {}\n",
    "    \n",
    "    for provider in agent.list_available_providers():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            result = agent.execute(\n",
    "                skill_name=skill_name,\n",
    "                user_message=user_message,\n",
    "                provider=provider\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            benchmarks[provider.value] = {\n",
    "                'elapsed_time': elapsed_time,\n",
    "                'response_length': len(result['response']),\n",
    "                'model': result['model']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            benchmarks[provider.value] = {'error': str(e)}\n",
    "    \n",
    "    return benchmarks\n",
    "\n",
    "# 벤치마크 실행\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"제공자별 성능 벤치마크\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "benchmark_message = \"Explain what machine learning is in simple terms.를 한국어로 번역해줘\"\n",
    "benchmark_results = benchmark_providers(agent, 'translator', benchmark_message)\n",
    "\n",
    "# 결과 출력\n",
    "for provider_name, metrics in benchmark_results.items():\n",
    "    print(f\"\\n[{provider_name.upper()}]\")\n",
    "    if 'error' in metrics:\n",
    "        print(f\"  에러: {metrics['error']}\")\n",
    "    else:\n",
    "        print(f\"  모델: {metrics['model']}\")\n",
    "        print(f\"  응답 시간: {metrics['elapsed_time']:.2f}초\")\n",
    "        print(f\"  응답 길이: {metrics['response_length']} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-11. 주요 차이점 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| 구분 | Claude API | OpenAI API |\n",
    "|------|------------|------------|\n",
    "| **System Prompt 처리** | `system` 파라미터로 분리 | `messages` 배열 내 `system` role |\n",
    "| **응답 구조** | `response.content[0].text` | `response.choices[0].message.content` |\n",
    "| **모델 네이밍** | `claude-sonnet-4-5` | `gpt-4o-mini`,|\n",
    "| **메시지 역할** | `user`, `assistant` | `system`, `user`, `assistant` |\n",
    "| **라이브러리** | `anthropic` | `openai` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
